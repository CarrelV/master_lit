{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info_about_run</th>\n",
       "      <th>training_dataset</th>\n",
       "      <th>text_tower_name</th>\n",
       "      <th>text_head_name</th>\n",
       "      <th>image_tower_name</th>\n",
       "      <th>image_head_name</th>\n",
       "      <th>text_tower_weight</th>\n",
       "      <th>text_head_weight</th>\n",
       "      <th>image_tower_weight</th>\n",
       "      <th>image_head_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>imageNet_0shot_small_top_1</th>\n",
       "      <th>imageNet_0shot_small_top_5</th>\n",
       "      <th>imageNet_0shot_tiny_top_1</th>\n",
       "      <th>imageNet_0shot_tiny_top_5</th>\n",
       "      <th>flickr30l_image2text_top_1</th>\n",
       "      <th>flickr30l_image2text_top_5</th>\n",
       "      <th>flickr30l_image2text_top_10</th>\n",
       "      <th>flickr30l_text2image_top_1</th>\n",
       "      <th>flickr30l_text2image_top_5</th>\n",
       "      <th>flickr30l_text2image_top_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline bad baseline</td>\n",
       "      <td>unknown (flickr?)</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>bad_baseline_text_enc_best_1.pt</td>\n",
       "      <td>bad_baseline_text_proj_best_1.pt</td>\n",
       "      <td>bad_baseline_img_enc_best_1.pt</td>\n",
       "      <td>bad_baseline_img_proj_best_1.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>6.343907</td>\n",
       "      <td>22.537563</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>31.149194</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>31.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline: baseline</td>\n",
       "      <td>unknown (flickr?)</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>prajjwal1/bert-medium</td>\n",
       "      <td>baseline_text_proj_best_1.pt</td>\n",
       "      <td>facebook/dino-vits16</td>\n",
       "      <td>baseline_img_proj_best_1.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>7.212020</td>\n",
       "      <td>28.914858</td>\n",
       "      <td>14.615385</td>\n",
       "      <td>52.307692</td>\n",
       "      <td>44.556452</td>\n",
       "      <td>83.568548</td>\n",
       "      <td>93.346774</td>\n",
       "      <td>46.975806</td>\n",
       "      <td>82.862903</td>\n",
       "      <td>94.254032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline: good baseline</td>\n",
       "      <td>unknown (flickr?)</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Small MLP Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>prajjwal1/bert-medium</td>\n",
       "      <td>good_baseline_text_proj_best_1.pt</td>\n",
       "      <td>facebook/dino-vits16</td>\n",
       "      <td>good_baseline_img_proj_best_1.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>5.809683</td>\n",
       "      <td>26.427379</td>\n",
       "      <td>16.794872</td>\n",
       "      <td>50.256410</td>\n",
       "      <td>43.951613</td>\n",
       "      <td>83.770161</td>\n",
       "      <td>94.556452</td>\n",
       "      <td>43.850806</td>\n",
       "      <td>83.064516</td>\n",
       "      <td>94.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline: APE</td>\n",
       "      <td>unknown (flickr?)</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Medium MLP Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>prajjwal1/bert-medium</td>\n",
       "      <td>APE_text_proj_best_1.pt</td>\n",
       "      <td>facebook/dino-vits16</td>\n",
       "      <td>APE_img_proj_best_1.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>6.677796</td>\n",
       "      <td>22.971619</td>\n",
       "      <td>18.205128</td>\n",
       "      <td>47.948718</td>\n",
       "      <td>40.524194</td>\n",
       "      <td>80.342742</td>\n",
       "      <td>93.245968</td>\n",
       "      <td>41.129032</td>\n",
       "      <td>80.241935</td>\n",
       "      <td>92.943548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LST (medium/medium), random init</td>\n",
       "      <td>MSCOCO</td>\n",
       "      <td>BERT base (108M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT base (86M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_baseBERT_ViTb_mscoco_LilT.pt</td>\n",
       "      <td>LST_text_proj_best_baseBERT_ViTb_mscoco_LilT.pt</td>\n",
       "      <td>LST_img_enc_best_baseBERT_ViTb_mscoco_LilT.pt</td>\n",
       "      <td>LST_img_proj_best_baseBERT_ViTb_mscoco_LilT.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>2.954925</td>\n",
       "      <td>17.245409</td>\n",
       "      <td>7.820513</td>\n",
       "      <td>36.538462</td>\n",
       "      <td>3.528226</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>31.854839</td>\n",
       "      <td>3.326613</td>\n",
       "      <td>16.330645</td>\n",
       "      <td>31.350806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LST (medium/medium), smart init</td>\n",
       "      <td>MSCOCO</td>\n",
       "      <td>BERT base (108M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT base (86M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_baseBERT_ViTb_mscoco_LilT_sm...</td>\n",
       "      <td>LST_text_proj_best_baseBERT_ViTb_mscoco_LilT_s...</td>\n",
       "      <td>LST_img_enc_best_baseBERT_ViTb_mscoco_LilT_sma...</td>\n",
       "      <td>LST_img_proj_best_baseBERT_ViTb_mscoco_LilT_sm...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.075125</td>\n",
       "      <td>19.482471</td>\n",
       "      <td>7.307692</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2.923387</td>\n",
       "      <td>17.943548</td>\n",
       "      <td>32.762097</td>\n",
       "      <td>2.822581</td>\n",
       "      <td>19.153226</td>\n",
       "      <td>34.979839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LST (I=medium/T=medium), longer training</td>\n",
       "      <td>unknown (MSCOCO?)</td>\n",
       "      <td>BERT base (108M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT base (86M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_LST_Imedium_Tmedium_complete.pt</td>\n",
       "      <td>LST_text_proj_best_LST_Imedium_Tmedium_complet...</td>\n",
       "      <td>LST_img_enc_best_LST_Imedium_Tmedium_complete.pt</td>\n",
       "      <td>LST_img_proj_best_LST_Imedium_Tmedium_complete.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>9.799666</td>\n",
       "      <td>35.525876</td>\n",
       "      <td>22.435897</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>39.818548</td>\n",
       "      <td>77.620968</td>\n",
       "      <td>90.725806</td>\n",
       "      <td>42.540323</td>\n",
       "      <td>76.814516</td>\n",
       "      <td>88.508065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LST (I=medium/T=medium), shorter training</td>\n",
       "      <td>unknown (MSCOCO? or maybe flickr?)</td>\n",
       "      <td>BERT base (108M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT base (86M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_LST_Imedium5_Tmedium3.pt</td>\n",
       "      <td>LST_text_proj_best_LST_Imedium5_Tmedium3.pt</td>\n",
       "      <td>LST_img_enc_best_LST_Imedium5_Tmedium3.pt</td>\n",
       "      <td>LST_img_proj_best_LST_Imedium5_Tmedium3.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>9.632721</td>\n",
       "      <td>35.242070</td>\n",
       "      <td>25.384615</td>\n",
       "      <td>68.974359</td>\n",
       "      <td>34.072581</td>\n",
       "      <td>71.068548</td>\n",
       "      <td>85.987903</td>\n",
       "      <td>34.576613</td>\n",
       "      <td>70.463710</td>\n",
       "      <td>83.266129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LST (I=medium/T=small)</td>\n",
       "      <td>unknown (MSCOCO?)</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT base (86M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_LST_Imedium_Tsmall.pt</td>\n",
       "      <td>LST_text_proj_best_LST_Imedium_Tsmall.pt</td>\n",
       "      <td>LST_img_enc_best_LST_Imedium_Tsmall.pt</td>\n",
       "      <td>LST_img_proj_best_LST_Imedium_Tsmall.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>6.043406</td>\n",
       "      <td>30.016694</td>\n",
       "      <td>18.205128</td>\n",
       "      <td>54.615385</td>\n",
       "      <td>24.495968</td>\n",
       "      <td>62.600806</td>\n",
       "      <td>80.745968</td>\n",
       "      <td>24.395161</td>\n",
       "      <td>62.399194</td>\n",
       "      <td>79.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LST (I=medium/T=small)</td>\n",
       "      <td>unknown (MSCOCO?), special lr5</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT base (86M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_LST_Imedium_Tsmall_lr5.pt</td>\n",
       "      <td>LST_text_proj_best_LST_Imedium_Tsmall_lr5.pt</td>\n",
       "      <td>LST_img_enc_best_LST_Imedium_Tsmall_lr5.pt</td>\n",
       "      <td>LST_img_proj_best_LST_Imedium_Tsmall_lr5.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>8.130217</td>\n",
       "      <td>32.921536</td>\n",
       "      <td>21.410256</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>39.516129</td>\n",
       "      <td>74.798387</td>\n",
       "      <td>86.895161</td>\n",
       "      <td>40.725806</td>\n",
       "      <td>73.790323</td>\n",
       "      <td>85.685484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LST (I=small/T=medium), lr3</td>\n",
       "      <td>unknown (MSCOCO?)</td>\n",
       "      <td>BERT base (108M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_LST_Ismall_Tmedium_lr3.pt</td>\n",
       "      <td>LST_text_proj_best_LST_Ismall_Tmedium_lr3.pt</td>\n",
       "      <td>LST_img_enc_best_LST_Ismall_Tmedium_lr3.pt</td>\n",
       "      <td>LST_img_proj_best_LST_Ismall_Tmedium_lr3.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>9.298831</td>\n",
       "      <td>30.884808</td>\n",
       "      <td>22.307692</td>\n",
       "      <td>62.820513</td>\n",
       "      <td>37.701613</td>\n",
       "      <td>71.774194</td>\n",
       "      <td>85.282258</td>\n",
       "      <td>37.298387</td>\n",
       "      <td>72.681452</td>\n",
       "      <td>84.576613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LST (I=medium/T=medium), lrI5,lrT3</td>\n",
       "      <td>cc3m</td>\n",
       "      <td>BERT base (108M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT base (86M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_LST_cc3m_I5_T3.pt</td>\n",
       "      <td>LST_text_proj_best_LST_cc3m_I5_T3.pt</td>\n",
       "      <td>LST_img_enc_best_LST_cc3m_I5_T3.pt</td>\n",
       "      <td>LST_img_proj_best_LST_cc3m_I5_T3.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>8.597663</td>\n",
       "      <td>34.207012</td>\n",
       "      <td>17.820513</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>30.947581</td>\n",
       "      <td>68.245968</td>\n",
       "      <td>82.358871</td>\n",
       "      <td>27.318548</td>\n",
       "      <td>61.290323</td>\n",
       "      <td>79.133065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LST (I=small/T=small)</td>\n",
       "      <td>flickr</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_flickr.pt</td>\n",
       "      <td>LST_text_proj_best_flickr.pt</td>\n",
       "      <td>LST_img_enc_best_flickr.pt</td>\n",
       "      <td>LST_img_proj_best_flickr.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>8.196995</td>\n",
       "      <td>32.520868</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>61.153846</td>\n",
       "      <td>62.903226</td>\n",
       "      <td>91.129032</td>\n",
       "      <td>96.169355</td>\n",
       "      <td>61.088710</td>\n",
       "      <td>90.826613</td>\n",
       "      <td>96.673387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LST (I=small/T=medium)</td>\n",
       "      <td>flickr</td>\n",
       "      <td>BERT base (108M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_flickr_baseBERT.pt</td>\n",
       "      <td>LST_text_proj_best_flickr_baseBERT.pt</td>\n",
       "      <td>LST_img_enc_best_flickr_baseBERT.pt</td>\n",
       "      <td>LST_img_proj_best_flickr_baseBERT.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>2.504174</td>\n",
       "      <td>19.031720</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>3.326613</td>\n",
       "      <td>15.927419</td>\n",
       "      <td>31.653226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LST (I=small/T=small)</td>\n",
       "      <td>MSCOCO</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_mscoco.pt</td>\n",
       "      <td>LST_text_proj_best_mscoco.pt</td>\n",
       "      <td>LST_img_enc_best_mscoco.pt</td>\n",
       "      <td>LST_img_proj_best_mscoco.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>8.614357</td>\n",
       "      <td>34.056761</td>\n",
       "      <td>20.256410</td>\n",
       "      <td>60.384615</td>\n",
       "      <td>38.205645</td>\n",
       "      <td>73.588710</td>\n",
       "      <td>87.298387</td>\n",
       "      <td>37.903226</td>\n",
       "      <td>71.774194</td>\n",
       "      <td>84.173387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LST (I=small/T=small), random init</td>\n",
       "      <td>MSCOCO</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_mscoco_randomInit.pt</td>\n",
       "      <td>LST_text_proj_best_mscoco_randomInit.pt</td>\n",
       "      <td>LST_img_enc_best_mscoco_randomInit.pt</td>\n",
       "      <td>LST_img_proj_best_mscoco_randomInit.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>7.295492</td>\n",
       "      <td>32.404007</td>\n",
       "      <td>23.974359</td>\n",
       "      <td>61.153846</td>\n",
       "      <td>37.903226</td>\n",
       "      <td>74.697581</td>\n",
       "      <td>86.995968</td>\n",
       "      <td>38.911290</td>\n",
       "      <td>72.983871</td>\n",
       "      <td>84.274194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LST (I=small/T=small), smart init</td>\n",
       "      <td>MSCOCO</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_mscoco_smartInit.pt</td>\n",
       "      <td>LST_text_proj_best_mscoco_smartInit.pt</td>\n",
       "      <td>LST_img_enc_best_mscoco_smartInit.pt</td>\n",
       "      <td>LST_img_proj_best_mscoco_smartInit.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>8.464107</td>\n",
       "      <td>31.452421</td>\n",
       "      <td>19.743590</td>\n",
       "      <td>60.769231</td>\n",
       "      <td>38.911290</td>\n",
       "      <td>72.479839</td>\n",
       "      <td>85.987903</td>\n",
       "      <td>38.709677</td>\n",
       "      <td>73.185484</td>\n",
       "      <td>84.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LST (I=small/T=small), smart init, low LR</td>\n",
       "      <td>MSCOCO</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LST_text_enc_best_mscoco_smartInit_lowLR.pt</td>\n",
       "      <td>LST_text_proj_best_mscoco_smartInit_lowLR.pt</td>\n",
       "      <td>LST_img_enc_best_mscoco_smartInit_lowLR.pt</td>\n",
       "      <td>LST_img_proj_best_mscoco_smartInit_lowLR.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>7.245409</td>\n",
       "      <td>30.200334</td>\n",
       "      <td>17.948718</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>39.314516</td>\n",
       "      <td>75.201613</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>38.205645</td>\n",
       "      <td>72.983871</td>\n",
       "      <td>85.383065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>APE (I=small/T=small),baseline</td>\n",
       "      <td>MSCOCO</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Medium MLP Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>prajjwal1/bert-medium</td>\n",
       "      <td>APE_text_proj_best_mscoco_1.pt</td>\n",
       "      <td>facebook/dino-vits16</td>\n",
       "      <td>APE_img_proj_best_mscoco_1.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>6.777963</td>\n",
       "      <td>33.005008</td>\n",
       "      <td>19.102564</td>\n",
       "      <td>61.282051</td>\n",
       "      <td>38.810484</td>\n",
       "      <td>74.395161</td>\n",
       "      <td>87.399194</td>\n",
       "      <td>40.725806</td>\n",
       "      <td>74.092742</td>\n",
       "      <td>85.987903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>APE (I=small/T=medium),baseline</td>\n",
       "      <td>MSCOCO</td>\n",
       "      <td>BERT base (108M)</td>\n",
       "      <td>Medium MLP Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>APE_text_proj_best_baseBERT_mscoco.pt</td>\n",
       "      <td>facebook/dino-vits16</td>\n",
       "      <td>APE_img_proj_best_baseBERT_mscoco.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>10.534224</td>\n",
       "      <td>37.629382</td>\n",
       "      <td>25.128205</td>\n",
       "      <td>65.256410</td>\n",
       "      <td>38.205645</td>\n",
       "      <td>74.395161</td>\n",
       "      <td>87.197581</td>\n",
       "      <td>39.213710</td>\n",
       "      <td>74.395161</td>\n",
       "      <td>86.895161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>benchmark classic LiT (I=small/T=medium)</td>\n",
       "      <td>flickr?</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>classic_LiT_text_enc_best_1.pt</td>\n",
       "      <td>classic_LiT_text_proj_best_1.pt</td>\n",
       "      <td>facebook/dino-vits16</td>\n",
       "      <td>classic_LiT_img_proj_best_1.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>8.130217</td>\n",
       "      <td>33.138564</td>\n",
       "      <td>17.307692</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>42.137097</td>\n",
       "      <td>74.596774</td>\n",
       "      <td>88.810484</td>\n",
       "      <td>41.129032</td>\n",
       "      <td>72.983871</td>\n",
       "      <td>86.693548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>benchmark classic LiT (costly version of weigh...</td>\n",
       "      <td>flickr?</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>costly_baseline_text_enc_best_1.pt</td>\n",
       "      <td>costly_baseline_text_proj_best_1.pt</td>\n",
       "      <td>facebook/dino-vits16</td>\n",
       "      <td>costly_baseline_img_proj_best_1.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>8.397329</td>\n",
       "      <td>32.454090</td>\n",
       "      <td>20.512821</td>\n",
       "      <td>54.487179</td>\n",
       "      <td>61.895161</td>\n",
       "      <td>93.145161</td>\n",
       "      <td>97.580645</td>\n",
       "      <td>62.600806</td>\n",
       "      <td>92.641129</td>\n",
       "      <td>97.681452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>benchmark LiT (small mlp instead of lin proj) ...</td>\n",
       "      <td>flickr?</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Small MLP Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LiT_text_enc_best_1.pt</td>\n",
       "      <td>LiT_text_proj_best_1.pt</td>\n",
       "      <td>facebook/dino-vits16</td>\n",
       "      <td>LiT_img_proj_best_1.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>8.547579</td>\n",
       "      <td>33.956594</td>\n",
       "      <td>21.282051</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>63.306452</td>\n",
       "      <td>91.129032</td>\n",
       "      <td>96.270161</td>\n",
       "      <td>64.919355</td>\n",
       "      <td>91.330645</td>\n",
       "      <td>96.673387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>benchmark LiT second run(small mlp instead of ...</td>\n",
       "      <td>flickr?</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Small MLP Head</td>\n",
       "      <td>ViT small (22M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>LiT_text_enc_best_2.pt</td>\n",
       "      <td>LiT_text_proj_best_2.pt</td>\n",
       "      <td>facebook/dino-vits16</td>\n",
       "      <td>LiT_img_proj_best_2.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>8.380634</td>\n",
       "      <td>35.258765</td>\n",
       "      <td>18.589744</td>\n",
       "      <td>62.692308</td>\n",
       "      <td>38.608871</td>\n",
       "      <td>75.907258</td>\n",
       "      <td>88.104839</td>\n",
       "      <td>40.423387</td>\n",
       "      <td>73.689516</td>\n",
       "      <td>86.995968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LoRA (I=medium/T=medium)</td>\n",
       "      <td>unknown (MSCOCO?)</td>\n",
       "      <td>BERT base (108M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT base (86M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>lora_text_enc_best_lora_I6medium_T4medium.pt</td>\n",
       "      <td>lora_text_proj_best_lora_I6medium_T4medium.pt</td>\n",
       "      <td>lora_img_enc_best_lora_I6medium_T4medium.pt</td>\n",
       "      <td>lora_img_proj_best_lora_I6medium_T4medium.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>11.001669</td>\n",
       "      <td>34.841402</td>\n",
       "      <td>21.794872</td>\n",
       "      <td>65.128205</td>\n",
       "      <td>48.588710</td>\n",
       "      <td>81.250000</td>\n",
       "      <td>91.733871</td>\n",
       "      <td>48.185484</td>\n",
       "      <td>81.955645</td>\n",
       "      <td>90.221774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LoRA cc3m (I=medium/T=medium)</td>\n",
       "      <td>cc3m</td>\n",
       "      <td>BERT base (108M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT base (86M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>lora_text_enc_best_lora_cc3m_I6_T4.pt</td>\n",
       "      <td>lora_text_proj_best_lora_cc3m_I6_T4.pt</td>\n",
       "      <td>lora_img_enc_best_lora_cc3m_I6_T4.pt</td>\n",
       "      <td>lora_img_proj_best_lora_cc3m_I6_T4.pt</td>\n",
       "      <td>...</td>\n",
       "      <td>8.247078</td>\n",
       "      <td>36.243740</td>\n",
       "      <td>19.743590</td>\n",
       "      <td>71.153846</td>\n",
       "      <td>37.096774</td>\n",
       "      <td>76.108871</td>\n",
       "      <td>90.826613</td>\n",
       "      <td>34.879032</td>\n",
       "      <td>73.891129</td>\n",
       "      <td>87.802419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LoRA mscoco (I=medium/T=small)</td>\n",
       "      <td>mscoco</td>\n",
       "      <td>BERT medium (42M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>ViT base (86M)</td>\n",
       "      <td>Projection Head</td>\n",
       "      <td>lora_text_enc_best_lora_mscoco_Imedium6_Tsmall...</td>\n",
       "      <td>lora_text_proj_best_lora_mscoco_Imedium6_Tsmal...</td>\n",
       "      <td>lora_img_enc_best_lora_mscoco_Imedium6_Tsmall4.pt</td>\n",
       "      <td>lora_img_proj_best_lora_mscoco_Imedium6_Tsmall...</td>\n",
       "      <td>...</td>\n",
       "      <td>8.297162</td>\n",
       "      <td>32.454090</td>\n",
       "      <td>15.512821</td>\n",
       "      <td>59.615385</td>\n",
       "      <td>44.657258</td>\n",
       "      <td>79.435484</td>\n",
       "      <td>90.826613</td>\n",
       "      <td>45.262097</td>\n",
       "      <td>78.326613</td>\n",
       "      <td>90.826613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       info_about_run  \\\n",
       "0                               baseline bad baseline   \n",
       "1                                  baseline: baseline   \n",
       "2                             baseline: good baseline   \n",
       "3                                       baseline: APE   \n",
       "4                    LST (medium/medium), random init   \n",
       "5                     LST (medium/medium), smart init   \n",
       "6            LST (I=medium/T=medium), longer training   \n",
       "7           LST (I=medium/T=medium), shorter training   \n",
       "8                              LST (I=medium/T=small)   \n",
       "9                              LST (I=medium/T=small)   \n",
       "10                        LST (I=small/T=medium), lr3   \n",
       "11                 LST (I=medium/T=medium), lrI5,lrT3   \n",
       "12                              LST (I=small/T=small)   \n",
       "13                             LST (I=small/T=medium)   \n",
       "14                              LST (I=small/T=small)   \n",
       "15                 LST (I=small/T=small), random init   \n",
       "16                  LST (I=small/T=small), smart init   \n",
       "17          LST (I=small/T=small), smart init, low LR   \n",
       "18                     APE (I=small/T=small),baseline   \n",
       "19                    APE (I=small/T=medium),baseline   \n",
       "20           benchmark classic LiT (I=small/T=medium)   \n",
       "21  benchmark classic LiT (costly version of weigh...   \n",
       "22  benchmark LiT (small mlp instead of lin proj) ...   \n",
       "23  benchmark LiT second run(small mlp instead of ...   \n",
       "24                           LoRA (I=medium/T=medium)   \n",
       "25                      LoRA cc3m (I=medium/T=medium)   \n",
       "26                     LoRA mscoco (I=medium/T=small)   \n",
       "\n",
       "                      training_dataset    text_tower_name   text_head_name  \\\n",
       "0                    unknown (flickr?)  BERT medium (42M)  Projection Head   \n",
       "1                    unknown (flickr?)  BERT medium (42M)  Projection Head   \n",
       "2                    unknown (flickr?)  BERT medium (42M)   Small MLP Head   \n",
       "3                    unknown (flickr?)  BERT medium (42M)  Medium MLP Head   \n",
       "4                               MSCOCO   BERT base (108M)  Projection Head   \n",
       "5                               MSCOCO   BERT base (108M)  Projection Head   \n",
       "6                    unknown (MSCOCO?)   BERT base (108M)  Projection Head   \n",
       "7   unknown (MSCOCO? or maybe flickr?)   BERT base (108M)  Projection Head   \n",
       "8                    unknown (MSCOCO?)  BERT medium (42M)  Projection Head   \n",
       "9       unknown (MSCOCO?), special lr5  BERT medium (42M)  Projection Head   \n",
       "10                   unknown (MSCOCO?)   BERT base (108M)  Projection Head   \n",
       "11                                cc3m   BERT base (108M)  Projection Head   \n",
       "12                              flickr  BERT medium (42M)  Projection Head   \n",
       "13                              flickr   BERT base (108M)  Projection Head   \n",
       "14                              MSCOCO  BERT medium (42M)  Projection Head   \n",
       "15                              MSCOCO  BERT medium (42M)  Projection Head   \n",
       "16                              MSCOCO  BERT medium (42M)  Projection Head   \n",
       "17                              MSCOCO  BERT medium (42M)  Projection Head   \n",
       "18                              MSCOCO  BERT medium (42M)  Medium MLP Head   \n",
       "19                              MSCOCO   BERT base (108M)  Medium MLP Head   \n",
       "20                             flickr?  BERT medium (42M)  Projection Head   \n",
       "21                             flickr?  BERT medium (42M)  Projection Head   \n",
       "22                             flickr?  BERT medium (42M)   Small MLP Head   \n",
       "23                             flickr?  BERT medium (42M)   Small MLP Head   \n",
       "24                   unknown (MSCOCO?)   BERT base (108M)  Projection Head   \n",
       "25                                cc3m   BERT base (108M)  Projection Head   \n",
       "26                              mscoco  BERT medium (42M)  Projection Head   \n",
       "\n",
       "   image_tower_name  image_head_name  \\\n",
       "0   ViT small (22M)  Projection Head   \n",
       "1   ViT small (22M)  Projection Head   \n",
       "2   ViT small (22M)  Projection Head   \n",
       "3   ViT small (22M)  Projection Head   \n",
       "4    ViT base (86M)  Projection Head   \n",
       "5    ViT base (86M)  Projection Head   \n",
       "6    ViT base (86M)  Projection Head   \n",
       "7    ViT base (86M)  Projection Head   \n",
       "8    ViT base (86M)  Projection Head   \n",
       "9    ViT base (86M)  Projection Head   \n",
       "10  ViT small (22M)  Projection Head   \n",
       "11   ViT base (86M)  Projection Head   \n",
       "12  ViT small (22M)  Projection Head   \n",
       "13  ViT small (22M)  Projection Head   \n",
       "14  ViT small (22M)  Projection Head   \n",
       "15  ViT small (22M)  Projection Head   \n",
       "16  ViT small (22M)  Projection Head   \n",
       "17  ViT small (22M)  Projection Head   \n",
       "18  ViT small (22M)  Projection Head   \n",
       "19  ViT small (22M)  Projection Head   \n",
       "20  ViT small (22M)  Projection Head   \n",
       "21  ViT small (22M)  Projection Head   \n",
       "22  ViT small (22M)  Projection Head   \n",
       "23  ViT small (22M)  Projection Head   \n",
       "24   ViT base (86M)  Projection Head   \n",
       "25   ViT base (86M)  Projection Head   \n",
       "26   ViT base (86M)  Projection Head   \n",
       "\n",
       "                                    text_tower_weight  \\\n",
       "0                     bad_baseline_text_enc_best_1.pt   \n",
       "1                               prajjwal1/bert-medium   \n",
       "2                               prajjwal1/bert-medium   \n",
       "3                               prajjwal1/bert-medium   \n",
       "4      LST_text_enc_best_baseBERT_ViTb_mscoco_LilT.pt   \n",
       "5   LST_text_enc_best_baseBERT_ViTb_mscoco_LilT_sm...   \n",
       "6   LST_text_enc_best_LST_Imedium_Tmedium_complete.pt   \n",
       "7          LST_text_enc_best_LST_Imedium5_Tmedium3.pt   \n",
       "8             LST_text_enc_best_LST_Imedium_Tsmall.pt   \n",
       "9         LST_text_enc_best_LST_Imedium_Tsmall_lr5.pt   \n",
       "10        LST_text_enc_best_LST_Ismall_Tmedium_lr3.pt   \n",
       "11                LST_text_enc_best_LST_cc3m_I5_T3.pt   \n",
       "12                        LST_text_enc_best_flickr.pt   \n",
       "13               LST_text_enc_best_flickr_baseBERT.pt   \n",
       "14                        LST_text_enc_best_mscoco.pt   \n",
       "15             LST_text_enc_best_mscoco_randomInit.pt   \n",
       "16              LST_text_enc_best_mscoco_smartInit.pt   \n",
       "17        LST_text_enc_best_mscoco_smartInit_lowLR.pt   \n",
       "18                              prajjwal1/bert-medium   \n",
       "19                                  bert-base-uncased   \n",
       "20                     classic_LiT_text_enc_best_1.pt   \n",
       "21                 costly_baseline_text_enc_best_1.pt   \n",
       "22                             LiT_text_enc_best_1.pt   \n",
       "23                             LiT_text_enc_best_2.pt   \n",
       "24       lora_text_enc_best_lora_I6medium_T4medium.pt   \n",
       "25              lora_text_enc_best_lora_cc3m_I6_T4.pt   \n",
       "26  lora_text_enc_best_lora_mscoco_Imedium6_Tsmall...   \n",
       "\n",
       "                                     text_head_weight  \\\n",
       "0                    bad_baseline_text_proj_best_1.pt   \n",
       "1                        baseline_text_proj_best_1.pt   \n",
       "2                   good_baseline_text_proj_best_1.pt   \n",
       "3                             APE_text_proj_best_1.pt   \n",
       "4     LST_text_proj_best_baseBERT_ViTb_mscoco_LilT.pt   \n",
       "5   LST_text_proj_best_baseBERT_ViTb_mscoco_LilT_s...   \n",
       "6   LST_text_proj_best_LST_Imedium_Tmedium_complet...   \n",
       "7         LST_text_proj_best_LST_Imedium5_Tmedium3.pt   \n",
       "8            LST_text_proj_best_LST_Imedium_Tsmall.pt   \n",
       "9        LST_text_proj_best_LST_Imedium_Tsmall_lr5.pt   \n",
       "10       LST_text_proj_best_LST_Ismall_Tmedium_lr3.pt   \n",
       "11               LST_text_proj_best_LST_cc3m_I5_T3.pt   \n",
       "12                       LST_text_proj_best_flickr.pt   \n",
       "13              LST_text_proj_best_flickr_baseBERT.pt   \n",
       "14                       LST_text_proj_best_mscoco.pt   \n",
       "15            LST_text_proj_best_mscoco_randomInit.pt   \n",
       "16             LST_text_proj_best_mscoco_smartInit.pt   \n",
       "17       LST_text_proj_best_mscoco_smartInit_lowLR.pt   \n",
       "18                     APE_text_proj_best_mscoco_1.pt   \n",
       "19              APE_text_proj_best_baseBERT_mscoco.pt   \n",
       "20                    classic_LiT_text_proj_best_1.pt   \n",
       "21                costly_baseline_text_proj_best_1.pt   \n",
       "22                            LiT_text_proj_best_1.pt   \n",
       "23                            LiT_text_proj_best_2.pt   \n",
       "24      lora_text_proj_best_lora_I6medium_T4medium.pt   \n",
       "25             lora_text_proj_best_lora_cc3m_I6_T4.pt   \n",
       "26  lora_text_proj_best_lora_mscoco_Imedium6_Tsmal...   \n",
       "\n",
       "                                   image_tower_weight  \\\n",
       "0                      bad_baseline_img_enc_best_1.pt   \n",
       "1                                facebook/dino-vits16   \n",
       "2                                facebook/dino-vits16   \n",
       "3                                facebook/dino-vits16   \n",
       "4       LST_img_enc_best_baseBERT_ViTb_mscoco_LilT.pt   \n",
       "5   LST_img_enc_best_baseBERT_ViTb_mscoco_LilT_sma...   \n",
       "6    LST_img_enc_best_LST_Imedium_Tmedium_complete.pt   \n",
       "7           LST_img_enc_best_LST_Imedium5_Tmedium3.pt   \n",
       "8              LST_img_enc_best_LST_Imedium_Tsmall.pt   \n",
       "9          LST_img_enc_best_LST_Imedium_Tsmall_lr5.pt   \n",
       "10         LST_img_enc_best_LST_Ismall_Tmedium_lr3.pt   \n",
       "11                 LST_img_enc_best_LST_cc3m_I5_T3.pt   \n",
       "12                         LST_img_enc_best_flickr.pt   \n",
       "13                LST_img_enc_best_flickr_baseBERT.pt   \n",
       "14                         LST_img_enc_best_mscoco.pt   \n",
       "15              LST_img_enc_best_mscoco_randomInit.pt   \n",
       "16               LST_img_enc_best_mscoco_smartInit.pt   \n",
       "17         LST_img_enc_best_mscoco_smartInit_lowLR.pt   \n",
       "18                               facebook/dino-vits16   \n",
       "19                               facebook/dino-vits16   \n",
       "20                               facebook/dino-vits16   \n",
       "21                               facebook/dino-vits16   \n",
       "22                               facebook/dino-vits16   \n",
       "23                               facebook/dino-vits16   \n",
       "24        lora_img_enc_best_lora_I6medium_T4medium.pt   \n",
       "25               lora_img_enc_best_lora_cc3m_I6_T4.pt   \n",
       "26  lora_img_enc_best_lora_mscoco_Imedium6_Tsmall4.pt   \n",
       "\n",
       "                                    image_head_weight  ...  \\\n",
       "0                     bad_baseline_img_proj_best_1.pt  ...   \n",
       "1                         baseline_img_proj_best_1.pt  ...   \n",
       "2                    good_baseline_img_proj_best_1.pt  ...   \n",
       "3                              APE_img_proj_best_1.pt  ...   \n",
       "4      LST_img_proj_best_baseBERT_ViTb_mscoco_LilT.pt  ...   \n",
       "5   LST_img_proj_best_baseBERT_ViTb_mscoco_LilT_sm...  ...   \n",
       "6   LST_img_proj_best_LST_Imedium_Tmedium_complete.pt  ...   \n",
       "7          LST_img_proj_best_LST_Imedium5_Tmedium3.pt  ...   \n",
       "8             LST_img_proj_best_LST_Imedium_Tsmall.pt  ...   \n",
       "9         LST_img_proj_best_LST_Imedium_Tsmall_lr5.pt  ...   \n",
       "10        LST_img_proj_best_LST_Ismall_Tmedium_lr3.pt  ...   \n",
       "11                LST_img_proj_best_LST_cc3m_I5_T3.pt  ...   \n",
       "12                        LST_img_proj_best_flickr.pt  ...   \n",
       "13               LST_img_proj_best_flickr_baseBERT.pt  ...   \n",
       "14                        LST_img_proj_best_mscoco.pt  ...   \n",
       "15             LST_img_proj_best_mscoco_randomInit.pt  ...   \n",
       "16              LST_img_proj_best_mscoco_smartInit.pt  ...   \n",
       "17        LST_img_proj_best_mscoco_smartInit_lowLR.pt  ...   \n",
       "18                      APE_img_proj_best_mscoco_1.pt  ...   \n",
       "19               APE_img_proj_best_baseBERT_mscoco.pt  ...   \n",
       "20                     classic_LiT_img_proj_best_1.pt  ...   \n",
       "21                 costly_baseline_img_proj_best_1.pt  ...   \n",
       "22                             LiT_img_proj_best_1.pt  ...   \n",
       "23                             LiT_img_proj_best_2.pt  ...   \n",
       "24       lora_img_proj_best_lora_I6medium_T4medium.pt  ...   \n",
       "25              lora_img_proj_best_lora_cc3m_I6_T4.pt  ...   \n",
       "26  lora_img_proj_best_lora_mscoco_Imedium6_Tsmall...  ...   \n",
       "\n",
       "    imageNet_0shot_small_top_1  imageNet_0shot_small_top_5  \\\n",
       "0                     6.343907                   22.537563   \n",
       "1                     7.212020                   28.914858   \n",
       "2                     5.809683                   26.427379   \n",
       "3                     6.677796                   22.971619   \n",
       "4                     2.954925                   17.245409   \n",
       "5                     5.075125                   19.482471   \n",
       "6                     9.799666                   35.525876   \n",
       "7                     9.632721                   35.242070   \n",
       "8                     6.043406                   30.016694   \n",
       "9                     8.130217                   32.921536   \n",
       "10                    9.298831                   30.884808   \n",
       "11                    8.597663                   34.207012   \n",
       "12                    8.196995                   32.520868   \n",
       "13                    2.504174                   19.031720   \n",
       "14                    8.614357                   34.056761   \n",
       "15                    7.295492                   32.404007   \n",
       "16                    8.464107                   31.452421   \n",
       "17                    7.245409                   30.200334   \n",
       "18                    6.777963                   33.005008   \n",
       "19                   10.534224                   37.629382   \n",
       "20                    8.130217                   33.138564   \n",
       "21                    8.397329                   32.454090   \n",
       "22                    8.547579                   33.956594   \n",
       "23                    8.380634                   35.258765   \n",
       "24                   11.001669                   34.841402   \n",
       "25                    8.247078                   36.243740   \n",
       "26                    8.297162                   32.454090   \n",
       "\n",
       "    imageNet_0shot_tiny_top_1  imageNet_0shot_tiny_top_5  \\\n",
       "0                    7.692308                  38.461538   \n",
       "1                   14.615385                  52.307692   \n",
       "2                   16.794872                  50.256410   \n",
       "3                   18.205128                  47.948718   \n",
       "4                    7.820513                  36.538462   \n",
       "5                    7.307692                  40.000000   \n",
       "6                   22.435897                  63.333333   \n",
       "7                   25.384615                  68.974359   \n",
       "8                   18.205128                  54.615385   \n",
       "9                   21.410256                  60.000000   \n",
       "10                  22.307692                  62.820513   \n",
       "11                  17.820513                  66.666667   \n",
       "12                  20.000000                  61.153846   \n",
       "13                   7.692308                  38.461538   \n",
       "14                  20.256410                  60.384615   \n",
       "15                  23.974359                  61.153846   \n",
       "16                  19.743590                  60.769231   \n",
       "17                  17.948718                  58.333333   \n",
       "18                  19.102564                  61.282051   \n",
       "19                  25.128205                  65.256410   \n",
       "20                  17.307692                  61.538462   \n",
       "21                  20.512821                  54.487179   \n",
       "22                  21.282051                  56.666667   \n",
       "23                  18.589744                  62.692308   \n",
       "24                  21.794872                  65.128205   \n",
       "25                  19.743590                  71.153846   \n",
       "26                  15.512821                  59.615385   \n",
       "\n",
       "    flickr30l_image2text_top_1  flickr30l_image2text_top_5  \\\n",
       "0                     3.125000                   15.625000   \n",
       "1                    44.556452                   83.568548   \n",
       "2                    43.951613                   83.770161   \n",
       "3                    40.524194                   80.342742   \n",
       "4                     3.528226                   15.625000   \n",
       "5                     2.923387                   17.943548   \n",
       "6                    39.818548                   77.620968   \n",
       "7                    34.072581                   71.068548   \n",
       "8                    24.495968                   62.600806   \n",
       "9                    39.516129                   74.798387   \n",
       "10                   37.701613                   71.774194   \n",
       "11                   30.947581                   68.245968   \n",
       "12                   62.903226                   91.129032   \n",
       "13                    3.125000                   15.625000   \n",
       "14                   38.205645                   73.588710   \n",
       "15                   37.903226                   74.697581   \n",
       "16                   38.911290                   72.479839   \n",
       "17                   39.314516                   75.201613   \n",
       "18                   38.810484                   74.395161   \n",
       "19                   38.205645                   74.395161   \n",
       "20                   42.137097                   74.596774   \n",
       "21                   61.895161                   93.145161   \n",
       "22                   63.306452                   91.129032   \n",
       "23                   38.608871                   75.907258   \n",
       "24                   48.588710                   81.250000   \n",
       "25                   37.096774                   76.108871   \n",
       "26                   44.657258                   79.435484   \n",
       "\n",
       "    flickr30l_image2text_top_10  flickr30l_text2image_top_1  \\\n",
       "0                     31.149194                    3.125000   \n",
       "1                     93.346774                   46.975806   \n",
       "2                     94.556452                   43.850806   \n",
       "3                     93.245968                   41.129032   \n",
       "4                     31.854839                    3.326613   \n",
       "5                     32.762097                    2.822581   \n",
       "6                     90.725806                   42.540323   \n",
       "7                     85.987903                   34.576613   \n",
       "8                     80.745968                   24.395161   \n",
       "9                     86.895161                   40.725806   \n",
       "10                    85.282258                   37.298387   \n",
       "11                    82.358871                   27.318548   \n",
       "12                    96.169355                   61.088710   \n",
       "13                    31.250000                    3.326613   \n",
       "14                    87.298387                   37.903226   \n",
       "15                    86.995968                   38.911290   \n",
       "16                    85.987903                   38.709677   \n",
       "17                    87.500000                   38.205645   \n",
       "18                    87.399194                   40.725806   \n",
       "19                    87.197581                   39.213710   \n",
       "20                    88.810484                   41.129032   \n",
       "21                    97.580645                   62.600806   \n",
       "22                    96.270161                   64.919355   \n",
       "23                    88.104839                   40.423387   \n",
       "24                    91.733871                   48.185484   \n",
       "25                    90.826613                   34.879032   \n",
       "26                    90.826613                   45.262097   \n",
       "\n",
       "    flickr30l_text2image_top_5  flickr30l_text2image_top_10  \n",
       "0                    15.625000                    31.250000  \n",
       "1                    82.862903                    94.254032  \n",
       "2                    83.064516                    94.354839  \n",
       "3                    80.241935                    92.943548  \n",
       "4                    16.330645                    31.350806  \n",
       "5                    19.153226                    34.979839  \n",
       "6                    76.814516                    88.508065  \n",
       "7                    70.463710                    83.266129  \n",
       "8                    62.399194                    79.838710  \n",
       "9                    73.790323                    85.685484  \n",
       "10                   72.681452                    84.576613  \n",
       "11                   61.290323                    79.133065  \n",
       "12                   90.826613                    96.673387  \n",
       "13                   15.927419                    31.653226  \n",
       "14                   71.774194                    84.173387  \n",
       "15                   72.983871                    84.274194  \n",
       "16                   73.185484                    84.375000  \n",
       "17                   72.983871                    85.383065  \n",
       "18                   74.092742                    85.987903  \n",
       "19                   74.395161                    86.895161  \n",
       "20                   72.983871                    86.693548  \n",
       "21                   92.641129                    97.681452  \n",
       "22                   91.330645                    96.673387  \n",
       "23                   73.689516                    86.995968  \n",
       "24                   81.955645                    90.221774  \n",
       "25                   73.891129                    87.802419  \n",
       "26                   78.326613                    90.826613  \n",
       "\n",
       "[27 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['info_about_run', 'text_tower_name', 'text_head_name',\n",
      "       'image_tower_name', 'image_head_name', 'text_tower_params',\n",
      "       'text_head_params', 'image_tower_params', 'image_head_params',\n",
      "       'text_tower_trainable_params', 'text_head_trainable_params',\n",
      "       'image_tower_trainable_params', 'image_head_trainable_params',\n",
      "       'memory_before_model', 'memory_for_model', 'memory_forward_pass',\n",
      "       'mem_after_loss_gradient', 'mem_after_loss_backward',\n",
      "       'mem_after_optimizer'],\n",
      "      dtype='object')\n",
      "             info_about_run    text_tower_name   text_head_name  \\\n",
      "0    LoRA (I=small/T=small)  BERT medium (42M)  Projection Head   \n",
      "1   LoRA (I=small/T=medium)   BERT base (108M)  Projection Head   \n",
      "2   LoRA (I=medium/T=small)  BERT medium (42M)  Projection Head   \n",
      "3  LoRA (I=medium/T=medium)   BERT base (108M)  Projection Head   \n",
      "4   LST (I=medium/T=medium)   BERT base (108M)  Projection Head   \n",
      "\n",
      "  image_tower_name  image_head_name  text_tower_params  text_head_params  \\\n",
      "0  ViT small (22M)  Projection Head           41635328            788224   \n",
      "1  ViT small (22M)  Projection Head          110072064           1050368   \n",
      "2   ViT base (86M)  Projection Head           41635328            788224   \n",
      "3   ViT base (86M)  Projection Head          110072064           1050368   \n",
      "4   ViT base (86M)  Projection Head          111267949           1050368   \n",
      "\n",
      "   image_tower_params  image_head_params  text_tower_trainable_params  \\\n",
      "0            22108416             657152                       262144   \n",
      "1            22108416             657152                       589824   \n",
      "2            86979072            1050368                       262144   \n",
      "3            86979072            1050368                       589824   \n",
      "4            88174957            1050368                      2376301   \n",
      "\n",
      "   text_head_trainable_params  image_tower_trainable_params  \\\n",
      "0                      788224                        294912   \n",
      "1                     1050368                        294912   \n",
      "2                      788224                        589824   \n",
      "3                     1050368                        589824   \n",
      "4                     1050368                       2377837   \n",
      "\n",
      "   image_head_trainable_params  memory_before_model  memory_for_model  \\\n",
      "0                       657152                    0         524306944   \n",
      "1                       657152                    0        1076269568   \n",
      "2                      1050368                    0        1044713984   \n",
      "3                      1050368                    0        1595496960   \n",
      "4                      1050368                    0        1653193216   \n",
      "\n",
      "   memory_forward_pass  mem_after_loss_gradient  mem_after_loss_backward  \\\n",
      "0           3377311232               3387883520                570099200   \n",
      "1           5310377472               5320949760               1123569152   \n",
      "2           5585404416               5596566528               1094897152   \n",
      "3           7519532032               7530104320               1645450752   \n",
      "4           4433719808               4445062144               1688714752   \n",
      "\n",
      "   mem_after_optimizer  \n",
      "0            587036160  \n",
      "1           1145355776  \n",
      "2           1116421632  \n",
      "3           1671693824  \n",
      "4           1743642112  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Variant'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/lit/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/lit/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/lit/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Variant'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m12\u001b[39m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Plotting memory usage across different metrics\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m df_pivot \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_usage_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m df_pivot\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, ax\u001b[38;5;241m=\u001b[39maxes[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     24\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMemory Usage Across Different Metrics\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/lit/lib/python3.10/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lit/lib/python3.10/site-packages/pandas/core/frame.py:8557\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   8551\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   8552\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   8553\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   8554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot\u001b[39m(\u001b[38;5;28mself\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   8555\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[0;32m-> 8557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lit/lib/python3.10/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lit/lib/python3.10/site-packages/pandas/core/reshape/pivot.py:511\u001b[0m, in \u001b[0;36mpivot\u001b[0;34m(data, index, columns, values)\u001b[0m\n\u001b[1;32m    509\u001b[0m         index_list \u001b[38;5;241m=\u001b[39m [Series(data\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname)]\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     index_list \u001b[38;5;241m=\u001b[39m [data[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m com\u001b[38;5;241m.\u001b[39mconvert_to_list_like(index)]\n\u001b[1;32m    513\u001b[0m data_columns \u001b[38;5;241m=\u001b[39m [data[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_listlike]\n\u001b[1;32m    514\u001b[0m index_list\u001b[38;5;241m.\u001b[39mextend(data_columns)\n",
      "File \u001b[0;32m~/miniconda3/envs/lit/lib/python3.10/site-packages/pandas/core/reshape/pivot.py:511\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    509\u001b[0m         index_list \u001b[38;5;241m=\u001b[39m [Series(data\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname)]\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     index_list \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m com\u001b[38;5;241m.\u001b[39mconvert_to_list_like(index)]\n\u001b[1;32m    513\u001b[0m data_columns \u001b[38;5;241m=\u001b[39m [data[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_listlike]\n\u001b[1;32m    514\u001b[0m index_list\u001b[38;5;241m.\u001b[39mextend(data_columns)\n",
      "File \u001b[0;32m~/miniconda3/envs/lit/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/lit/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Variant'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset from the CSV file\n",
    "df = pd.read_csv('memory.csv')\n",
    "\n",
    "# Print the first few rows and column names to understand the structure of your dataset\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "print(df.head())\n",
    "\n",
    "# Assuming your dataset has the following columns (adjust if needed):\n",
    "# 'Model' for model names\n",
    "# 'Variant' for size variants (e.g., small, medium, large, xlarge)\n",
    "# 'Memory_Usage_1', 'Memory_Usage_2', ... for different memory usage metrics\n",
    "\n",
    "# Replace the actual column names from your CSV\n",
    "model_col = 'Model'\n",
    "variant_col = 'Variant'\n",
    "memory_usage_cols = [col for col in df.columns if 'Memory_Usage' in col]\n",
    "\n",
    "# Set up the plot for memory usage across different metrics\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# Plotting memory usage across different metrics\n",
    "df_pivot = df.pivot(index=variant_col, columns=model_col, values=memory_usage_cols)\n",
    "df_pivot.plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Memory Usage Across Different Metrics')\n",
    "axes[0].set_xlabel('Variant')\n",
    "axes[0].set_ylabel('Memory Usage (GB)')\n",
    "\n",
    "# Plotting memory usage per model variant\n",
    "for model in df[model_col].unique():\n",
    "    model_data = df[df[model_col] == model]\n",
    "    model_data.plot(x=variant_col, y=memory_usage_cols, kind='bar', ax=axes[1], label=model, alpha=0.7)\n",
    "\n",
    "axes[1].set_title('Memory Usage per Model Variant')\n",
    "axes[1].set_xlabel('Variant')\n",
    "axes[1].set_ylabel('Memory Usage (GB)')\n",
    "axes[1].legend(df[model_col].unique())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import get_dataloader\n",
    "import config as CFG\n",
    "from tokenizer import get_tokenizer,get_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.utils import download_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./flickr30k/flickr30k_val.json\n"
     ]
    }
   ],
   "source": [
    "val = 'https://storage.googleapis.com/sfr-vision-language-research/datasets/flickr30k_val.json'\n",
    "download_url(val,CFG.ann_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024%1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.66666666666667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*500/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import CLIPModel\n",
    "from losses import CLIPLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vits16 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at prajjwal1/bert-medium were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "test = CLIPModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"prajjwal1/bert-medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-medium were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BertModel(config=BertConfig.from_pretrained(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-medium were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model3 = BertModel.from_pretrained(pretrained_model_name_or_path=model_name,config=BertConfig.from_pretrained(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_dataset\n",
    "from training import valid_one_epoch\n",
    "import os\n",
    "import config as CFG\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(224,pad_if_needed=True),\n",
    "            transforms.RandomHorizontalFlip(), \n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize((0.444, 0.421, 0.385), \n",
    "                                 (0.285, 0.277, 0.286))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./flickr30k/flickr30k_train.json\n",
      "Using downloaded and verified file: ./flickr30k/flickr30k_val.json\n",
      "Using downloaded and verified file: ./flickr30k/flickr30k_test.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(CFG.text_model_name)\n",
    "ds_train = get_dataset(tokenizer=tokenizer,transform=transform_train,split=\"train\")\n",
    "ds_val = get_dataset(tokenizer=tokenizer,transform=transform_train,split=\"val\")\n",
    "ds_test = get_dataset(tokenizer=tokenizer,transform=transform_train,split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([128])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([128])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print(ds_train.__getitem__(0)[\"image\"].shape)\n",
    "print(ds_train.__getitem__(0)[\"input_ids\"].shape)\n",
    "print(ds_val.__getitem__(0)[\"image\"].shape)\n",
    "print(ds_val.__getitem__(0)[\"input_ids\"].shape)\n",
    "print(ds_test.__getitem__(0)[\"image\"].shape)\n",
    "print(ds_test.__getitem__(0)[\"input_ids\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vincent/unifr/master_thesis/master_lit/temp.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/master_thesis/master_lit/temp.ipynb#ch0000012vscode-remote?line=0'>1</a>\u001b[0m dataloader_valid \u001b[39m=\u001b[39m get_dataloader(tokenizer\u001b[39m=\u001b[39mtokenizer,batch_size\u001b[39m=\u001b[39mCFG\u001b[39m.\u001b[39mbatch_size,shuffle\u001b[39m=\u001b[39mCFG\u001b[39m.\u001b[39mshuffle_train,num_workers\u001b[39m=\u001b[39mCFG\u001b[39m.\u001b[39mnum_workers,split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/master_thesis/master_lit/temp.ipynb#ch0000012vscode-remote?line=1'>2</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/master_thesis/master_lit/temp.ipynb#ch0000012vscode-remote?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m CLIPModel()\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "dataloader_valid = get_dataloader(tokenizer=tokenizer,batch_size=CFG.batch_size,shuffle=CFG.shuffle_train,num_workers=CFG.num_workers,split=\"val\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CLIPModel().to(device)\n",
    "loss_fn = CLIPLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcarrelv\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vincent/unifr/master_thesis/master_lit/wandb/run-20221014_142414-2ybe3au6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/carrelv/master_test_1/runs/2ybe3au6\" target=\"_blank\">easy-oath-31</a></strong> to <a href=\"https://wandb.ai/carrelv/master_test_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.84s/it, valid_loss=6.94]\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"master_test_1\",\n",
    "           config={\n",
    "               \"batch_size\": CFG.batch_size,\n",
    "               \"learning_rate\": CFG.head_lr,\n",
    "               \"dataset\": \"flickr30k\",\n",
    "           },\n",
    "           group=\"group_test\")\n",
    "    \n",
    "valid_loss = valid_one_epoch(model,loss_fn,dataloader_valid,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0927,  0.3875, -0.1741,  ...,  0.0377,  0.0927, -0.1575],\n",
       "        [-0.1718,  0.1364, -0.2955,  ..., -0.2148, -0.1264, -0.2588],\n",
       "        [-0.0938,  0.0679, -0.3672,  ...,  0.0347,  0.0078, -0.3171],\n",
       "        ...,\n",
       "        [-0.3468,  0.3004, -0.2342,  ..., -0.1646, -0.2120, -0.2403],\n",
       "        [-0.0600,  0.5362,  0.0269,  ..., -0.0285,  0.1017, -0.2270],\n",
       "        [-0.2309,  0.0847, -0.0814,  ..., -0.4008, -0.2727, -0.2470]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loss.avg_text_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./flickr30k/flickr30k_train.json\n",
      "Using downloaded and verified file: ./flickr30k/flickr30k_val.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vits16 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at prajjwal1/bert-medium were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(CFG.text_model_name)\n",
    "feature_extractor = get_feature_extractor(CFG.vision_model_name)\n",
    "\n",
    "dataloader_train = get_dataloader(tokenizer=tokenizer,feature_extractor=feature_extractor,batch_size=CFG.batch_size,shuffle=CFG.shuffle_train,num_workers=CFG.num_workers,split=\"train\")\n",
    "dataloader_valid = get_dataloader(tokenizer=tokenizer,feature_extractor=feature_extractor,batch_size=CFG.batch_size,shuffle=CFG.shuffle_train,num_workers=CFG.num_workers,split=\"val\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CLIPModel().to(device)\n",
    "loss_fn = CLIPLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1, 3, 224, 224])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(224,pad_if_needed=True),\n",
    "            transforms.RandomHorizontalFlip(), \n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./flickr30k/flickr30k_train.json\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(tokenizer=tokenizer,feature_extractor=feature_extractor,transform=transform_train,split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 3, 224, 224])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"image\"][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import  Dataset\n",
    "import json\n",
    "from dataset import pre_caption\n",
    "import config as CFG\n",
    "from torchvision.datasets import Flickr30k\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class flickr30k_test(Dataset):\n",
    "    def __init__(self, tokenizer,transform,image_root, ann_root, split, max_words=CFG.max_length, prompt=CFG.prompt):        \n",
    "        '''\n",
    "        image_root (string): Root directory of images (e.g. data/)\n",
    "        ann_root (string): directory to store the annotation file\n",
    "        split (string): one of \"train\" or \"test\"\n",
    "        '''        \n",
    "        train = 'https://storage.googleapis.com/sfr-vision-language-research/datasets/flickr30k_train.json'\n",
    "        test = 'https://storage.googleapis.com/sfr-vision-language-research/datasets/flickr30k_test.json'\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.split = split\n",
    "        assert self.split in (\"train\",\"test\")\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            url = train\n",
    "            filename = 'flickr30k_train.json'\n",
    "        else:\n",
    "            url = test\n",
    "            filename = 'flickr30k_test.json'\n",
    "\n",
    "        download_url(url,ann_root)\n",
    "        \n",
    "        self.annotation = json.load(open(os.path.join(ann_root,filename),'r'))\n",
    "        self.transform = transform\n",
    "        self.image_root = image_root\n",
    "        self.max_words = max_words      \n",
    "        self.prompt = prompt\n",
    "        \n",
    "        self.img_ids = {} \n",
    "\n",
    "        for ann in self.annotation:\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.img_ids.keys():\n",
    "                self.img_ids[img_id] = ann\n",
    "                self.img_ids[img_id][\"caption\"] = [self.img_ids[img_id][\"caption\"]]\n",
    "            \n",
    "            else: \n",
    "                ls = self.img_ids[img_id][\"caption\"]\n",
    "                ls.append(ann[\"caption\"])               \n",
    "                self.img_ids[img_id][\"caption\"] = ls\n",
    "\n",
    "        self.annotation = None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "    \n",
    "    def __getitem__(self, index):    \n",
    "        \n",
    "        item = self.img_ids[index]\n",
    "        \n",
    "        image_path = os.path.join(self.image_root,item['image'])        \n",
    "        image = Image.open(image_path).convert('RGB')   \n",
    "        image = self.transform(image)\n",
    "        \n",
    "        caption = self.prompt+pre_caption(random.choice(item['caption']), self.max_words)\n",
    "        \n",
    "        caption_encoded = self.tokenizer(caption,padding=\"max_length\",max_length=self.max_words)\n",
    "\n",
    "        return {\"image\" :image, \"input_ids\": torch.as_tensor(caption_encoded[\"input_ids\"]), \"attention_mask\": torch.as_tensor(caption_encoded[\"attention_mask\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./flickr30k/flickr30k_train.json\n"
     ]
    }
   ],
   "source": [
    "ds = flickr30k_test(tokenizer=tokenizer,transform=transform_train,image_root=CFG.image_root,ann_root=CFG.ann_root,split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vincent/unifr/master_thesis/master_lit/temp.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/master_thesis/master_lit/temp.ipynb#ch0000018vscode-remote?line=0'>1</a>\u001b[0m ds\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;32m/home/vincent/unifr/master_thesis/master_lit/temp.ipynb Cell 11'\u001b[0m in \u001b[0;36mflickr30k_test.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/master_thesis/master_lit/temp.ipynb#ch0000015vscode-remote?line=50'>51</a>\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_ids[index]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/master_thesis/master_lit/temp.ipynb#ch0000015vscode-remote?line=52'>53</a>\u001b[0m image_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_root,item[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m])        \n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/master_thesis/master_lit/temp.ipynb#ch0000015vscode-remote?line=53'>54</a>\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(image_path)\u001b[39m.\u001b[39mconvert(\u001b[39m'\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m'\u001b[39m)   \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/master_thesis/master_lit/temp.ipynb#ch0000015vscode-remote?line=54'>55</a>\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/master_thesis/master_lit/temp.ipynb#ch0000015vscode-remote?line=56'>57</a>\u001b[0m caption \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt\u001b[39m+\u001b[39mpre_caption(random\u001b[39m.\u001b[39mchoice(item[\u001b[39m'\u001b[39m\u001b[39mcaption\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_words)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two young, White males are outside near many bushes.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(ds.img_ids[0][\"caption\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import flickr30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./flickr30k/flickr30k_train.json\n"
     ]
    }
   ],
   "source": [
    "ds2 = flickr30k(tokenizer=tokenizer,transform=transform_train,image_root=CFG.image_root,ann_root=CFG.ann_root,split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': 'flickr30k-images/1000092795.jpg',\n",
       "  'caption': 'Two young guys with shaggy hair look at their hands while hanging out in the yard.',\n",
       "  'image_id': 0},\n",
       " {'image': 'flickr30k-images/1000092795.jpg',\n",
       "  'caption': 'Two young, White males are outside near many bushes.',\n",
       "  'image_id': 0},\n",
       " {'image': 'flickr30k-images/1000092795.jpg',\n",
       "  'caption': 'Two men in green shirts are standing in a yard.',\n",
       "  'image_id': 0},\n",
       " {'image': 'flickr30k-images/1000092795.jpg',\n",
       "  'caption': 'A man in a blue shirt standing in a garden.',\n",
       "  'image_id': 0},\n",
       " {'image': 'flickr30k-images/1000092795.jpg',\n",
       "  'caption': 'Two friends enjoy time spent together.',\n",
       "  'image_id': 0}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2.annotation[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4a9f4c4ce030a60d5e9e4103a5ecbe6be356f825e2c4ec21bb33804c21bc9e1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('lit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
