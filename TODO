DONE Change the gatting from sigmoid to tanh to have more like control net, no impact from side in the beggining
DONE Add final skip connection
DONE Correct the last hidden to side ladder which where wrong by one
DONE implement small transformer head on top instead of MLP
DONE test small transformer head to see if possible (WARNING already quite big)
DONE Change the 0 shot classification task to higher level class to test
DONE train LST_text on MSCOCO 
DONE retrain LST_text on MSCOCO with same epoch as LiT for fair comparison
DONE train LiT on MSCOCO to compare
DONE implement LoRA clip model 

DONE correct transformer head error in config

DONE train Transformer Head with 1 layer on flickr (if good, we continue with LST with smaller layer, for example only 2 layers 1&5 vs 4&8)

DONE Check if we go with smaller number of layer
DONE Bert base uncased

IN PROCESS use bigger data set cc3m
DONE use bigger text encoder for LST for the same memory budget than the current LiT text encoder 

IN PROCESS train base BERT on flickr30k
implement LST for ViT
train complete LST on flickr
train double LST on MSCOCO with all ladder
train double LST on MSCOCO with cut ladder first
train double LST on MSCOCO with cut ladder last

Search SOTA/literature for task which require image and text together
LST fusion?