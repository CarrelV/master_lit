DONE Change the gatting from sigmoid to tanh to have more like control net, no impact from side in the beggining
DONE Add final skip connection
DONE Correct the last hidden to side ladder which where wrong by one
DONE implement small transformer head on top instead of MLP
DONE test small transformer head to see if possible (WARNING already quite big)
DONE Change the 0 shot classification task to higher level class to test
DONE train LST_text on MSCOCO 
DONE retrain LST_text on MSCOCO with same epoch as LiT for fair comparison
DONE train LiT on MSCOCO to compare
DONE implement LoRA clip model 
# Not needed train LoRA model

DONE correct transformer head error in config

DONE train Transformer Head with 1 layer on flickr (if good, we continue with LST with smaller layer, for example only 2 layers 1&5 vs 4&8)

IN PROCESS Check if we go with smaller number of layer
DONE Bert base uncased

1 use bigger data set cc3m
DONE use bigger text encoder for LST for the same memory budget than the current LiT text encoder 
If still not beating, LoRA instead of LST
at the end use bigger image ViT for both (LiT and LST)
